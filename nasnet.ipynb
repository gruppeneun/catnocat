{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nasnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SbodT0FnI1V"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL2NMS44nPav"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhGs2tZmn5MR"
      },
      "source": [
        "import os\n",
        "\n",
        "# Location of Zip File\n",
        "drive_path = '/content/drive/My Drive/Colab Notebooks/catnocat/data.zip'\n",
        "local_path = '/content/catnocat'\n",
        "\n",
        "if not os.path.isdir(local_path):\n",
        "  os.mkdir(local_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKJqjgjFn7a5"
      },
      "source": [
        "# Copy the zip file from the google drive\n",
        "!cp '{drive_path}' '{local_path}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7QG1tdin9Ku"
      },
      "source": [
        "# Navigate to the copied file and unzip it quietly\n",
        "os.chdir(local_path)\n",
        "!unzip -q 'data.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj_k5iZln-kN"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjm_qD8YoDdD"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, GlobalAveragePooling2D, Dropout\n",
        "from keras.applications import NASNetMobile\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X10TOvPssMSe"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "import datetime, os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryyQiHHvsOA5"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjLvdx8TsYIJ"
      },
      "source": [
        "Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwpOEKRYsQOf"
      },
      "source": [
        "IMG_WIDTH = 224\n",
        "IMG_HEIGHT = 224\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "image_size = (IMG_WIDTH, IMG_HEIGHT)\n",
        "batch_size = 32\n",
        "\n",
        "num_epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4su38jESsUex"
      },
      "source": [
        "Read the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOjjDPk1sWf0"
      },
      "source": [
        "data_path = '/content/catnocat/data'\n",
        "\n",
        "train_data_path = os.path.join(data_path, 'train')\n",
        "valid_data_path = os.path.join(data_path, 'valid')\n",
        "# holytest_data_path = os.path.join(data_path, 'holytest')\n",
        "\n",
        "print(\"Path to training set: \", train_data_path)\n",
        "print(\"Path to validation set: \", valid_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H5ReRxPshfD"
      },
      "source": [
        "# Set Data Generator for training, testing and validation.\n",
        "\n",
        "# Note for testing, set shuffle = false (For proper Confusion matrix)\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "train_dataset = train_datagen.flow_from_directory(train_data_path,\n",
        "                                                  target_size=image_size,\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=True)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "valid_dataset = valid_datagen.flow_from_directory(valid_data_path,\n",
        "                                                  target_size=image_size,\n",
        "                                                  batch_size=batch_size,\n",
        "                                                  class_mode='categorical',\n",
        "                                                  shuffle=False)\n",
        "\n",
        "# test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "# test_dataset = test_datagen.flow_from_directory(holytest_data_path,\n",
        "#                                                 target_size=image_size,\n",
        "#                                                 batch_size=batch_size,\n",
        "#                                                 class_mode='categorical',\n",
        "#                                                 shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUj6Gt9KtKxS"
      },
      "source": [
        "Display the NASNet Mobile CNN Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJbxjdV1spkW"
      },
      "source": [
        "base_model = NASNetMobile(weights='imagenet',\n",
        "                       include_top=False,\n",
        "                       input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))  # imports the NASNetMobile model and discards the last 1000 neuron layer."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cx90kKWszj9"
      },
      "source": [
        "# check the architecture\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    print(i, layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjOxoUMSs6LA"
      },
      "source": [
        "Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GyzviTOs1Ah"
      },
      "source": [
        "def display_accuracy_plot(model_results):\n",
        "  acc = model_results.history['accuracy']\n",
        "  val_acc = model_results.history['val_accuracy']\n",
        "\n",
        "  loss = model_results.history['loss']\n",
        "  val_loss = model_results.history['val_loss']\n",
        "\n",
        "  epochs_range = range(len(model_results.history['accuracy']))\n",
        "\n",
        "  plt.figure(figsize=(15, 6))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs_range, loss, label='Training Loss')\n",
        "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4F1QAOOT0zKE"
      },
      "source": [
        "Compile & Train the Model\n",
        "Model Variant 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C69DUpC1JhK"
      },
      "source": [
        "Model Variant 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfr19xaC1K0O"
      },
      "source": [
        "model_variant = 1\n",
        "\n",
        "def model1_maker():\n",
        "    base_model = NASNetMobile(include_top=False,\n",
        "                           input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    \n",
        "    for layer in base_model.layers[:]:\n",
        "        layer.trainable = False\n",
        "\n",
        "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
        "    custom_model = base_model(input)\n",
        "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
        "    custom_model = Dense(64, activation='relu')(custom_model)\n",
        "    custom_model = Dropout(0.5)(custom_model)\n",
        "    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
        "    return Model(inputs=input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWH6d-LbvqMN"
      },
      "source": [
        "# Compile and train the model.\n",
        "model = model1_maker()\n",
        "\n",
        "model.compile(optimizer='Adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnmP5r1Jvux1"
      },
      "source": [
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ibgle1MvxV_"
      },
      "source": [
        "# Initialize Tensorboard:\n",
        "\n",
        "logdir = os.path.join(\"logs\", f'variant{model_variant}_'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLHY9n6dvzlM"
      },
      "source": [
        "# Start the training.\n",
        "\n",
        "epochs = num_epochs\n",
        "step_size_train = train_dataset.n // train_dataset.batch_size\n",
        "history = model.fit(train_dataset,\n",
        "                    steps_per_epoch=step_size_train,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=valid_dataset,\n",
        "                    callbacks=[tensorboard_callback]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiZnV4SJv14a"
      },
      "source": [
        "# Save the model\n",
        "model.save(f'cats_nasnetmobile_variant{model_variant}.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnxsmU8Yv4dz"
      },
      "source": [
        "display_accuracy_plot(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYgkCzgo2R26"
      },
      "source": [
        "Summarize Results with TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bc16lfX2VVY"
      },
      "source": [
        "%tensorboard --logdir logs "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0bCYcaz2X92"
      },
      "source": [
        "Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWN6tgc82XXb"
      },
      "source": [
        "# load the \"best\" model to visualize some predictions based on the validation set\n",
        "model = tf.keras.models.load_model('cats_nasnetmobile_variant1.hdf5')\n",
        "\n",
        "### Hier Model 0 oder 1 auswÃ¤hlen, schauen welches als besser ist. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxNBj3gR2hhn"
      },
      "source": [
        "Prediction - Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC2ezuph2cg7"
      },
      "source": [
        "# PREDICTION\n",
        "Y_pred = model.predict_generator(valid_dataset, step_size_train + 1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnct9FhR2k8-"
      },
      "source": [
        "# Confusion Matrix and Classification Report\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(valid_dataset.classes, y_pred))\n",
        "print('Classification Report')\n",
        "class_names = list(valid_dataset.class_indices.keys())\n",
        "print(classification_report(valid_dataset.classes, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "em_1yAN52mw7"
      },
      "source": [
        "# Plot the confusion matrix. Set Normalize = True/False\n",
        "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm = np.around(cm, decimals=2)\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rlYHbs32pQ4"
      },
      "source": [
        "# Confusion Matrix\n",
        "print('Confusion Matrix')\n",
        "cm = confusion_matrix(valid_dataset.classes, y_pred)\n",
        "plot_confusion_matrix(cm, class_names, title='Confusion Matrix')\n",
        "\n",
        "# Print Classification Report\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(valid_dataset.classes, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtWsYJt02qQr"
      },
      "source": [
        "Predictions - Explore classified images from Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeMlBU932tkG"
      },
      "source": [
        "# PREDICTIONS 2\n",
        "ground_truth = valid_dataset.classes\n",
        "print(ground_truth[:10])\n",
        "print(len(ground_truth))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faPpbBrn2vvf"
      },
      "source": [
        "# Then we get the predictions. This will be a list of probability values that express how confident\n",
        "# the model is about the presence of each category in each image. This step might take several minutes.\n",
        "\n",
        "predictions = model.predict_generator(valid_dataset,\n",
        "                                      steps=None)\n",
        "print(predictions[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rzC0WzT20dY"
      },
      "source": [
        "prediction_table = {}\n",
        "for index, val in enumerate(predictions):\n",
        "    index_of_highest_probability = np.argmax(val)\n",
        "    value_of_highest_probability = val[index_of_highest_probability]\n",
        "    prediction_table[index] = [\n",
        "        value_of_highest_probability,\n",
        "        index_of_highest_probability,\n",
        "        ground_truth[index]\n",
        "    ]\n",
        "assert len(predictions) == len(ground_truth) == len(prediction_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEHauPl524AF"
      },
      "source": [
        "def reverse_dict(class_dict):\n",
        "  reversed = {}\n",
        "  for key, value in class_dict.items():\n",
        "    reversed[value] = key\n",
        "  return reversed\n",
        "\n",
        "def get_images_with_sorted_probabilities(prediction_table,\n",
        "                                         get_highest_probability,\n",
        "                                         label,\n",
        "                                         number_of_items,\n",
        "                                         only_false_predictions=False):\n",
        "    sorted_prediction_table = [(k, prediction_table[k])\n",
        "                               for k in sorted(prediction_table,\n",
        "                                               key=prediction_table.get,\n",
        "                                               reverse=get_highest_probability)\n",
        "                               ]\n",
        "    result = []\n",
        "    for index, key in enumerate(sorted_prediction_table):\n",
        "        image_index, [probability, predicted_index, gt] = key\n",
        "        if predicted_index == label:\n",
        "            if only_false_predictions == True:\n",
        "                if predicted_index != gt:\n",
        "                    result.append(\n",
        "                        [image_index, [probability, predicted_index, gt]])\n",
        "            else:\n",
        "                result.append(\n",
        "                    [image_index, [probability, predicted_index, gt]])\n",
        "    return result[:number_of_items]\n",
        "\n",
        "\n",
        "def plot_images(filenames, distances, classification_txt, title_txt):\n",
        "    images = []\n",
        "    for filename in filenames:\n",
        "        images.append(mpimg.imread(filename))\n",
        "    plt.figure(figsize=(20, 24))\n",
        "    columns = 5\n",
        "    for i, image in enumerate(images):\n",
        "        ax = plt.subplot(int(len(images) / columns + 1), columns, i + 1)\n",
        "        ax.set_title(\"\\n\\n\" + filenames[i].split(\"/\")[-1] + \n",
        "                     \"\\n\" + classification_txt + \n",
        "                     \"\\nprobability=\" + str(float(\"{0:.2f}\".format(distances[i])))\n",
        "                     )\n",
        "        plt.suptitle(title_txt, fontsize=20, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "filenames = valid_dataset.filenames\n",
        "class_dict = reverse_dict(valid_dataset.class_indices)\n",
        "\n",
        "def display(sorted_indices, title_txt):\n",
        "    similar_image_paths = []\n",
        "    distances = []\n",
        "    for name, value in sorted_indices:\n",
        "        [probability, predicted_index, gt] = value\n",
        "        if predicted_index == gt:\n",
        "            classification_txt = \"CORRECT\"\n",
        "        else:\n",
        "            classification_txt = \"WRONG\"\n",
        "        classification_txt = \"{}\\nground truth: {}\\npredicted: {}\".format(classification_txt, \n",
        "                                                                 class_dict[gt].upper(), \n",
        "                                                                 class_dict[predicted_index].upper())\n",
        "        similar_image_paths.append(os.path.join(valid_data_path, filenames[name]))\n",
        "        distances.append(probability)\n",
        "    plot_images(similar_image_paths, distances, classification_txt, title_txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubWKzL6D26t6"
      },
      "source": [
        "img_list = get_images_with_sorted_probabilities(prediction_table,\n",
        "                                                             get_highest_probability=True,\n",
        "                                                             label=0,\n",
        "                                                             number_of_items=20,\n",
        "                                                             only_false_predictions=False)\n",
        "message = 'Images with highest probability of containing cats'\n",
        "display(img_list, message)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNOOcU4n29AM"
      },
      "source": [
        "img_list = get_images_with_sorted_probabilities(prediction_table,\n",
        "                                                             get_highest_probability=True,\n",
        "                                                             label=1,\n",
        "                                                             number_of_items=20,\n",
        "                                                             only_false_predictions=False)\n",
        "message = 'Images with highest probability of containing no cats'\n",
        "display(img_list, message)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfHyApEK2_RQ"
      },
      "source": [
        "img_list = get_images_with_sorted_probabilities(prediction_table,\n",
        "                                                        get_highest_probability=False,\n",
        "                                                        label=1,\n",
        "                                                        number_of_items=20,\n",
        "                                                        only_false_predictions=True)\n",
        "message = 'Wrongly classified images, with lowest probability'\n",
        "display(img_list, message)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJafThx33BQj"
      },
      "source": [
        "img_list = get_images_with_sorted_probabilities(prediction_table,\n",
        "                                                        get_highest_probability=False,\n",
        "                                                        label=0,\n",
        "                                                        number_of_items=20,\n",
        "                                                        only_false_predictions=True)\n",
        "message = 'Wrongly classified images, with lowest probability'\n",
        "display(img_list, message)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}